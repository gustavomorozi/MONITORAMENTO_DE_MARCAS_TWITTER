{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 7101,
     "status": "ok",
     "timestamp": 1572803534352,
     "user": {
      "displayName": "Gustavo Morozi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mByW0rsjc2JLOgtMEJbLYI-wp-fX33YcI07IA3b2g=s64",
      "userId": "12380855071894952955"
     },
     "user_tz": 120
    },
    "id": "3_ALg-Uc5dvZ",
    "outputId": "651bc27e-3023-4b5f-98f3-87e402acfe0a"
   },
   "outputs": [],
   "source": [
    "# Importando as bibliotecas \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import twitter\n",
    "import json\n",
    "import nltk\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "%matplotlib inline\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_twitter = pd.read_csv(\"BaseTwitter -ORIGINAL.csv\",sep=\",\",encoding=\"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_treinamento, base_teste=train_test_split(df_twitter)  #75% para treino e 25% para teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamanho da base de Treinamento 2998\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "alegria     1583\n",
       "tristeza    1415\n",
       "Name: Sentimento, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transforma base em pandas\n",
    "Analise_Treinamento=pd.DataFrame(base_treinamento)\n",
    "\n",
    "#Dá nome as colunas\n",
    "Analise_Treinamento.columns=['Frase','Sentimento']\n",
    "\n",
    "# Mostra tamanho da base de treinamento\n",
    "print('Tamanho da base de Treinamento {}'.format(Analise_Treinamento.shape[0]))\n",
    "\n",
    "# Mostra quantidade de cada tipo de sentimento\n",
    "Analise_Treinamento.Sentimento.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alegria     52.801868\n",
      "tristeza    47.198132\n",
      "Name: Sentimento, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Percentual de cada tipo de sentimento\n",
    "print((Analise_Treinamento.Sentimento.value_counts()/Analise_Treinamento.shape[0])*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamanho da base de Teste 1000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "alegria     503\n",
       "tristeza    497\n",
       "Name: Sentimento, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Criar base teste\n",
    "# Transforma base em pandas\n",
    "Analise_Teste=pd.DataFrame(base_teste)\n",
    "\n",
    "#Dá nome as colunas\n",
    "Analise_Teste.columns=['Frase','Sentimento']\n",
    "\n",
    "# Mostra tamanho da base de treinamento\n",
    "print('Tamanho da base de Teste {}'.format(Analise_Teste.shape[0]))\n",
    "\n",
    "# Mostra quantidade de cada tipo de sentimento\n",
    "Analise_Teste.Sentimento.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['de', 'a', 'o', 'que', 'e', 'é', 'do', 'da', 'em', 'um', 'para',\n",
       "       'com', 'não', 'uma', 'os', 'no', 'se', 'na', 'por', 'mais', 'as',\n",
       "       'dos', 'como', 'mas', 'ao', 'ele', 'das', 'à', 'seu', 'sua', 'ou',\n",
       "       'quando', 'muito', 'nos', 'já', 'eu', 'também', 'só', 'pelo',\n",
       "       'pela', 'até', 'isso', 'ela', 'entre', 'depois', 'sem', 'mesmo',\n",
       "       'aos', 'seus', 'quem', 'nas', 'me', 'esse', 'eles', 'você', 'essa',\n",
       "       'num', 'nem', 'suas', 'meu', 'às', 'minha', 'numa', 'pelos',\n",
       "       'elas', 'qual', 'nós', 'lhe', 'deles', 'essas', 'esses', 'pelas',\n",
       "       'este', 'dele', 'tu', 'te', 'vocês', 'vos', 'lhes', 'meus',\n",
       "       'minhas', 'teu', 'tua', 'teus', 'tuas', 'nosso', 'nossa', 'nossos',\n",
       "       'nossas', 'dela', 'delas', 'esta', 'estes', 'estas', 'aquele',\n",
       "       'aquela', 'aqueles', 'aquelas', 'isto', 'aquilo', 'estou', 'está',\n",
       "       'estamos', 'estão', 'estive', 'esteve', 'estivemos', 'estiveram',\n",
       "       'estava', 'estávamos', 'estavam', 'estivera', 'estivéramos',\n",
       "       'esteja', 'estejamos', 'estejam', 'estivesse', 'estivéssemos',\n",
       "       'estivessem', 'estiver', 'estivermos', 'estiverem', 'hei', 'há',\n",
       "       'havemos', 'hão', 'houve', 'houvemos', 'houveram', 'houvera',\n",
       "       'houvéramos', 'haja', 'hajamos', 'hajam', 'houvesse',\n",
       "       'houvéssemos', 'houvessem', 'houver', 'houvermos', 'houverem',\n",
       "       'houverei', 'houverá', 'houveremos', 'houverão', 'houveria',\n",
       "       'houveríamos', 'houveriam', 'sou', 'somos', 'são', 'era', 'éramos',\n",
       "       'eram', 'fui', 'foi', 'fomos', 'foram', 'fora', 'fôramos', 'seja',\n",
       "       'sejamos', 'sejam', 'fosse', 'fôssemos', 'fossem', 'for', 'formos',\n",
       "       'forem', 'serei', 'será', 'seremos', 'serão', 'seria', 'seríamos',\n",
       "       'seriam', 'tenho', 'tem', 'temos', 'tém', 'tinha', 'tínhamos',\n",
       "       'tinham', 'tive', 'teve', 'tivemos', 'tiveram', 'tivera',\n",
       "       'tivéramos', 'tenha', 'tenhamos', 'tenham', 'tivesse',\n",
       "       'tivéssemos', 'tivessem', 'tiver', 'tivermos', 'tiverem', 'terei',\n",
       "       'terá', 'teremos', 'terão', 'teria', 'teríamos', 'teriam'],\n",
       "      dtype='<U12')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#nltk.download('stopwords')\n",
    "lista_Stop=nltk.corpus.stopwords.words('portuguese')\n",
    "np.transpose(lista_Stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função que retira StopWords\n",
    "def RemoveStopWords(texto):\n",
    "    frases=[]\n",
    "    for (palavras, sentimento) in texto:\n",
    "        #Criamos uma list compreheension para extrair apenas as palavras que não estão na list_stop\n",
    "        semStop= [ p for p in palavras.split() if p not in lista_Stop]\n",
    "        #Inserindo as frases com os Labels (sentimento) ja tatadas pela Lista_Stop\n",
    "        frases.append((semStop,sentimento))\n",
    "    return frases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Steemer= técnica de remover sufixos e prefixos de uma palavra,Por exemplo, o stem da palavra cooking é cook. Um bom algoritmo sabe que “ing” é um sufixo e pode ser removido.\n",
    "#nltk.download('rslp')\n",
    "def aplica_Stemmer(texto):\n",
    "    stemmer=nltk.stem.RSLPStemmer()\n",
    "    #Escolhido o RSLPS pois é especifico da língua portuguesas\n",
    "    frases_sem_Stemming=[]\n",
    "    for (palavras, sentimento) in texto:\n",
    "        com_Stemming=[str(stemmer.stem(p)) for p in palavras.split() if p not in lista_Stop]\n",
    "        frases_sem_Stemming.append((com_Stemming,sentimento))\n",
    "    return frases_sem_Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transforma base de treinamento em um array\n",
    "base_treinamento=np.array(base_treinamento)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplica o Stemer na Frase\n",
    "# Transformar em vetor está dando problema\n",
    "frases_com_Stem_treinamento=aplica_Stemmer(base_treinamento)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transforma base de teste em um array\n",
    "base_teste=np.array(base_teste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplica Stem na base de teste\n",
    "frases_com_Stem_teste=aplica_Stemmer(base_teste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cria função para retornar as palavras da frase, sem a classificação(sentimento)\n",
    "def busca_Palavras(frases):\n",
    "    todas_Palavras=[]\n",
    "    for (palavras,sentimento) in frases:\n",
    "        todas_Palavras.extend(palavras)\n",
    "    return todas_Palavras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplica função acima em cada base\n",
    "palavras_treinamento=busca_Palavras(frases_com_Stem_treinamento)\n",
    "palavras_teste=busca_Palavras(frases_com_Stem_teste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantidade de palavras Treinamento 0    37342\n",
      "dtype: int64\n",
      "Quantidade de palavras Teste 0    12622\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Mostra quantidade de palavras na base\n",
    "print (\"Quantidade de palavras Treinamento {}\".format(pd.DataFrame(palavras_treinamento).count()))\n",
    "print (\"Quantidade de palavras Teste {}\".format(pd.DataFrame(palavras_teste).count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para verificar a quantidade de vezes que a palavras é mencionada\n",
    "def busca_frequencia(palavras):\n",
    "    palavras=nltk.FreqDist(palavras)\n",
    "    return palavras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chama função acima\n",
    "frequencia_treinamento=busca_frequencia(palavras_treinamento)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('iphon', 2936),\n",
       " ('compr', 568),\n",
       " ('quebr', 484),\n",
       " ('troq', 434),\n",
       " ('ganh', 434),\n",
       " ('estrag', 389),\n",
       " ('nã£', 385),\n",
       " ('molh', 363),\n",
       " ('pra', 340),\n",
       " ('q', 331),\n",
       " ('celul', 308),\n",
       " ('consert', 305),\n",
       " ('meu', 296),\n",
       " ('caiu', 290),\n",
       " ('ã©', 258),\n",
       " ('iphone,', 246),\n",
       " ('eu', 237),\n",
       " (',', 183),\n",
       " ('arrum', 182),\n",
       " ('to', 182)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A função most_common do NLTK possibilita visualizar quais as palavras que ocorrem com maior frequência em nosso texto.\n",
    "frequencia_treinamento.most_common(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Executa função parecida com a mostcommon\n",
    "frequencia_teste=busca_frequencia(palavras_teste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para retornar somente as palavras unicas\n",
    "def busca_palavras_unicas(frequencia):\n",
    "    freq=frequencia.keys()\n",
    "    return freq\n",
    "\n",
    "# Chama função acima\n",
    "palavras_unicas_treinamento=busca_palavras_unicas(frequencia_treinamento)\n",
    "palavras_unicas_teste=busca_palavras_unicas(frequencia_teste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cria função para identificar quais as palavras únicas estão no docuemnto passado para a função\n",
    "def extrator_palavras(documento):\n",
    "        #Utilizado set() para associar a variável doc.com o parametro que esta chegando\n",
    "        doc=set(documento)\n",
    "        caracteristicas={}\n",
    "        for palavras in palavras_unicas_treinamento:\n",
    "            caracteristicas['%s' % palavras]=(palavras in doc)\n",
    "        return caracteristicas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# devido a necessidade de aplciação da função Extrato_Palavras sobre as bases de Treinamento e Teste, como a variável palavras_unicas_teste exige aplicação isolada, precisamos criar uma função apartada somente\n",
    "# para a base de teste\n",
    "def extrator_palavras_teste(documento):\n",
    "    doc=set(documento)\n",
    "    caracteristicas={}\n",
    "    for palavras in palavras_unicas_teste:\n",
    "        caracteristicas['%s' % palavras]=(palavras in doc)\n",
    "    return caracteristicas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_completa_treinamento=nltk.classify.apply_features(extrator_palavras, frases_com_Stem_treinamento)\n",
    "base_completa_teste=nltk.classify.apply_features(extrator_palavras_teste,frases_com_Stem_teste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['alegria', 'tristeza']\n"
     ]
    }
   ],
   "source": [
    "# O algoritmo NaiveBayes monta a tabela de probabilidade\n",
    "classificador=nltk.NaiveBayesClassifier.train(base_completa_treinamento)\n",
    "print(classificador.labels())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "                       @ = True           triste : alegri =     64.5 : 1.0\n",
      "                    caiu = True           triste : alegri =     44.8 : 1.0\n",
      "                  estrag = True           triste : alegri =     41.6 : 1.0\n",
      "                 consert = True           alegri : triste =     22.3 : 1.0\n",
      "                       . = True           triste : alegri =     19.9 : 1.0\n",
      "                       ' = True           triste : alegri =     19.8 : 1.0\n",
      "                     cha = True           triste : alegri =     19.8 : 1.0\n",
      "                  derrub = True           triste : alegri =     17.7 : 1.0\n",
      "                     ess = True           triste : alegri =     15.4 : 1.0\n",
      "                    troq = True           alegri : triste =     13.1 : 1.0\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(classificador.show_most_informative_features(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9829886591060707\n"
     ]
    }
   ],
   "source": [
    "# Verifica a acuracia do modelo com a base de treinamento\n",
    "print(nltk.classify.accuracy(classificador,base_completa_treinamento))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agrega linhas com erros de classificação\n",
    "erros=[]\n",
    "for (frase,classe) in base_completa_treinamento:\n",
    "    #print(frase)\n",
    "    #print(classe)\n",
    "    resultado=classificador.classify(frase)\n",
    "    if resultado != classe:\n",
    "        erros.append((classe,resultado,frase))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         |         t |\n",
      "         |    a    r |\n",
      "         |    l    i |\n",
      "         |    e    s |\n",
      "         |    g    t |\n",
      "         |    r    e |\n",
      "         |    i    z |\n",
      "         |    a    a |\n",
      "---------+-----------+\n",
      " alegria |<1571>  12 |\n",
      "tristeza |   39<1376>|\n",
      "---------+-----------+\n",
      "(row = reference; col = test)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Cria matriz de confusão para de treinamento\n",
    "from nltk.metrics import ConfusionMatrix\n",
    "esperado=[]\n",
    "previsto=[]\n",
    "for teste in base_completa_treinamento:\n",
    "    resultado=classificador.classify(teste[0])\n",
    "    previsto.append(resultado)\n",
    "    esperado.append(teste[1])\n",
    "\n",
    "matriz=ConfusionMatrix(esperado,previsto)\n",
    "print (matriz)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         |       t |\n",
      "         |   a   r |\n",
      "         |   l   i |\n",
      "         |   e   s |\n",
      "         |   g   t |\n",
      "         |   r   e |\n",
      "         |   i   z |\n",
      "         |   a   a |\n",
      "---------+---------+\n",
      " alegria |<487> 16 |\n",
      "tristeza |  21<476>|\n",
      "---------+---------+\n",
      "(row = reference; col = test)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Cria matriz de confusão para de teste\n",
    "from nltk.metrics import ConfusionMatrix\n",
    "esperado=[]\n",
    "previsto=[]\n",
    "for teste in base_completa_teste:\n",
    "    resultado=classificador.classify(teste[0])\n",
    "    previsto.append(resultado)\n",
    "    esperado.append(teste[1])\n",
    "matriz=ConfusionMatrix(esperado,previsto)\n",
    "\n",
    "print (matriz)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alegria: 0.722784\n",
      "tristeza: 0.277216\n",
      "Resultado final: alegria\n"
     ]
    }
   ],
   "source": [
    "teste=\"Comprei um celular novo!\"\n",
    "testeStemming=[]\n",
    "stemmer=nltk.stem.RSLPStemmer()\n",
    "for (palavras_treinamento) in teste.split():\n",
    "    comStem=[p for p in palavras_treinamento.split()]\n",
    "    testeStemming.append(str(stemmer.stem(comStem[0])))\n",
    "\n",
    "novo=extrator_palavras(testeStemming)\n",
    "#print(classificador.classify(novo))\n",
    "distribuicao = classificador.prob_classify(novo)\n",
    "resultado_final=classificador.classify(novo)\n",
    "for classe in distribuicao.samples():\n",
    "    print('%s: %f' % (classe, distribuicao.prob(classe)))\n",
    "    \n",
    "print(\"Resultado final: \"+ resultado_final)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "LendoTwitter.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
